{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Introduction to Reddit Data\n",
    "\n",
    "## Contents\n",
    "1. [Setup](#Section-1%3A-Setup)\n",
    "    1. [Import](#1.1-Import-Packages)\n",
    "    1. [Getting Data](#1.2-Getting-Data)\n",
    "    1. [Obscenity](#1.3-Obscenity)\n",
    "1. [Exploring Data](#Section-2%3A-Exploring-Data)\n",
    "    1. [Variables](#2.1-Variables)\n",
    "    1. [Distributions](#2.2-Distributions)\n",
    "1. [Trends over Time](#Section-3%3A-Trends-over-Time)\n",
    "    1. [Adding Events](#3.1-Adding-Events)\n",
    "    1. [Events in Detail](#3.1-Events-in-Detail)\n",
    "1. [Football games](#Sectoin-4%3A-Football-games)\n",
    "\n",
    "\n",
    "**Suggested Readings:**\n",
    "\n",
    "Popular and short writing:\n",
    "1. Hern, Alex. 2014. \"Reddit women protest at new front-page position.\" The Guardian, 13 May. https://www.theguardian.com/technology/2014/may/13/reddit-women-protest-front-page-subforum-subreddit-position\n",
    "\n",
    "Academic publications:\n",
    "1. Palmer, Alexis, Melissa Robinson, and Kristy Philips. 2017. ‚ÄúIllegal Is Not a Noun: Linguistic Form for Detection of Pejorative Nominalizations.‚Äù Pp. 91‚Äì100 in Proceedings of the First Workshop on Abusive Language Online. Vancouver.\n",
    "2. Danescu-Niculescu-Mizil, Cristian, et al. 2013. \"A computational approach to politeness with application to social factors.\" Proceedings of ACL.\n",
    "3. Chandrasekharan, Eshwar. 2017. \"You Can't Stay Here: The Efficacy of Reddit's 2015 Ban Examined Through Hate Speech.\" Proceedings of the ACM on Human-Computer Interaction, Volume 1 Issue CSCW.\n",
    "\n",
    "\n",
    "## Section 0: Background\n",
    "We'll cover:\n",
    "- What reddit data look like\n",
    "- Several ways to summarize the conversation's tone\n",
    "- Evaluation of data over time\n",
    "\n",
    "Online communities can portray trends in current societal interests and discourse. With these communities being online, researchers are capable of easily analyzing and parsing through data to quantify these trends.  In this lab, we will be discussing way to measure changes in specific online communities on Reddit through scoring and comparison measures.  These scores have been generated by a variety of researchers through calculations and likelihood measures.  The specific calculations and scores will be detailed in the lab and more information can be found in the provided links.  \n",
    "\n",
    "We will then plot trends in these online communities to get a better understanding of correlations and how time impacts user involvement.  Visualizing these trends through plotting will also lead into the following labs where we will go more in depth regarding community behavior.\n",
    "\n",
    "## Section 1: Setup\n",
    "### 1.1 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Getting Data\n",
    "- Data files with Reddit comments are publicly available many places online, including torrents, google's BigQuery, and several data hosting websites. UM keeps a full copy in our Advanced Research Computing resources.\n",
    "- Reddit is one of the biggest sites on the internet. \n",
    "    - It has over 3.5 billion comments, and the data take up several TB of disk space (`1 TB = 1024 GB`)! \n",
    "    - This makes working with the data difficult.\n",
    "    - For simplicity, we went ahead and used some big data tools like `pyspark` and `hadoop` to go through all the comments and select out smaller sets to work with in this lab. \n",
    "- Let's start by looking at just the comments from the subreddit community for the University of Michigan\n",
    "    - This file is only 34 MB: a more managable size!\n",
    "    - The `shape` property tells us that there are 66 thousand rows (comments) and 28 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "um_comments = pd.read_csv('data/merged/uofm.tsv.gz', sep='\\t')\n",
    "\n",
    "#convert our dates to the date data type\n",
    "um_comments['date'] = pd.to_datetime(um_comments.date)\n",
    "#show the shape of our table\n",
    "um_comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Obscenity\n",
    "- The data for this lab include comments taken from the internet. Some of these comments might have obscene or offensive language in them.\n",
    "- For the most part, we will look at statistics summarizing the comments.\n",
    "- Sometimes, though, we will look at example comments chosen at random from the data.\n",
    "- **Important:** if you do not want to see comments with obscene or offensive language, then change the code in the cell below to say `show_obscene = False`.\n",
    "    - The code will try to pick examples without obscenity when it is showing random examples. Because people on the internet can type anything, often in unusual ways, we cannot promise every obscene or offensive comment will be filtered out, but a lot of them will be.\n",
    "    - This has no affect on the statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_obscene = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Exploring Data\n",
    "### 2.1 Variables\n",
    "What information do we have about each comment?\n",
    "- We have a lot! Here are some of the most interesting columns:\n",
    "    - `body` the text of the comment\n",
    "    - `author` the username of the person who posted it\n",
    "    - `date` when the comment was made\n",
    "    - `subreddit` which community a comment is from. Here, they're all from `r/uofm`\n",
    "    - `politeness` scores, computed by the [Stanford NLP group's software](https://www.cs.cornell.edu/~cristian/Politeness.html), tell us how \"polite\" a comment is, from 0 (not at all) to 1 (very polite). The program that gives these scores was designed primarily for comments where someone was replying to a request.\n",
    "        - politeness scores are based on the indication of polite words, phrases, and communication strategies, instead of detecting impolite ones. In other words, 0 politeness does not necessarily mean impoliteness but lack of polite words.\n",
    "    - `sentiment` (how positive or negative a comment is), computed by the [VADER program in NLTK](http://www.nltk.org/_modules/nltk/sentiment/vader.html). (-1 is very negative, 0 is neutral, and 1 is very positive). \n",
    "        - VADER uses a bag of words approach, i.e. a lookup table of positive and negative words. Sentiment is calculated based on the occurrence of negative or positive words in texts, and the intensity of the sentiment will increase if words like ‚Äúreally‚Äù, ‚Äúso‚Äù or ‚Äúa bit‚Äù are present.\n",
    "    - `pej_nouns`: Sometimes when an adjective for people is used as a noun, it takes on a pejorative meaning. Research has found this is often true for the words \"female,\" \"gay,\" \"poor,\" and \"illegal,\" so this column counts the number of times those words (or versions of them like \"females\") are used as nouns. For more information, see this paper:\n",
    "        - Palmer, Alexis, Melissa Robinson, and Kristy Philips. 2017. ‚Äú[Illegal Is Not a Noun: Linguistic Form for Detection of Pejorative Nominalizations](http://www.aclweb.org/anthology/W17-3014).‚Äù Pp. 91‚Äì100 in *Proceedings of the First Workshop on Abusive Language Online.* Vancouver.\n",
    "    - Several scores from the [Perspective API](https://www.perspectiveapi.com/). In this project, Google and Jigsaw teamed up to build automatic systems for finding bad comments. We used their program to score these comments already, and the scores are saved in the file.\n",
    "        - `ATTACK_ON_COMMENTER` the probability that this comment is a personal attack on another commenter \n",
    "        - `INCOHERENT` whether the comment seems to make sense (high values don't make sense).\n",
    "        - `INFLAMMATORY` how inflammatory the comment is\n",
    "        - `LIKELY_TO_REJECT` the liklihood that New York Times comment editors would reject  the comment if it was posted on their site \n",
    "        - `OBSCENE` probability that the comment is obscene\n",
    "            - Obscene or vulgar language such as cursing.\n",
    "            - \"A higher score indicates a greater likelihood a reader would perceive the comment as containing the given attribute.\" (From [Perspective API](https://developers.perspectiveapi.com/s/about-the-api-model-cards))\n",
    "        - `TOXICITY` probability that the comment is 'toxic' for community discussion\n",
    "            - Perspective defines toxicity as \"a rude, disrespectful, or unreasonable comment that is likely to make you leave a discussion.\" (From [Perspective API](https://developers.perspectiveapi.com/s/about-the-api-model-cards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example comments\n",
    "- This randomly selects one of the comments and shows the text. \n",
    "- Run it multiple times to see different randomly chosen comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(um_comments.sample(1).body.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function for finding examples of comments that score high or low\n",
    "Run this code and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example(data, column, where='high', show_obscene=True):\n",
    "    #pick whether to use high or low scoring comments\n",
    "    if where == 'high':\n",
    "        asc = False\n",
    "    else:\n",
    "        asc = True\n",
    "    #Select the 100 most extreme comments in this column\n",
    "    df = data.sort_values(by=column, ascending=asc).head(100)\n",
    "    \n",
    "    if not show_obscene:\n",
    "        df = df[df.OBSCENE < 0.1]\n",
    "    \n",
    "    if df.shape[0] > 0:\n",
    "        #pick one at random and print the text of it\n",
    "        print(df.sample(1).body.iloc[0])\n",
    "    else:\n",
    "        print('No comments meet your search criteria.')\n",
    "        if not show_obscene:\n",
    "            print('The obscenity filter might be hiding these comments. You can try turning it off if you would like to read them. Simply set \"show_obscene=True\"')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    \n",
    "#### Short Answer 1:\n",
    "    \n",
    "What do all those scores mean? (They're not perfect!)\n",
    "- **Run the code below, trying different column names** to see examples of comments that scored high or low in each measure.  \n",
    "    - The function `get_example()` picks a comment at random, so run it more than once with `alt`+`enter` and you'll see different comments.\n",
    "    - Look for patterns in the types of comments that come up.\n",
    "    - Do any of the scores seem to mean something a little different than you expected?\n",
    "   \n",
    "    Do you think that these examples are representative of/aligns with the score given? In a few sentences for each one, tell us **which** score you chose and how it is or isn't representative of the score.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='sentiment', where='high', show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='sentiment', where='low', show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='politeness', where='low', show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, \n",
    "            column='ATTACK_ON_COMMENTER', where='high', show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='TOXICITY', where='high', show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='OBSCENE', where='high', show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that the scores don't always seem right. For example, sometimes a comment that scored high in `ATTACK_ON_COMMENTER` isn't actually a personal attack.\n",
    "    - The scores were made by some of the most advanced software for this in the world, and they're still not perfect. This reminds us just how hard it is for computers to understand human language.\n",
    "- Still, most of the scores seem about right. And, as we know from statistics, we can still make inferences about average scores even when there are some errors in our measurements."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distributions\n",
    "Getting a feel for our data\n",
    "- One of the first things to do with any data is plot it. We want to get a feel for what's in it and how it is spread out (i.e. how it is distributed). Take a look at the histograms below.\n",
    "- Below, we plot the distribution of sentiment scores and the distribution of obscentity scores.\n",
    "- There are a few important things to notice:\n",
    "    - Sentiment ranges from -1 to +1. That is, people can make very negative or very positive comments, or anything in between.\n",
    "    - Sentiment looks like what we call a \"normal distribution\" or a \"bell curve.\" Most sentiment scores are around 0.2. Only a small number of comments have an extremely negative or extremely positive score.\n",
    "    - There is a big \"spike\" at 0 for sentiment. Usually, when you see a something like this in data is is a result of how the measurements were taken. In this case, comments get a score of 0 if they don't seem to have a positive or negative sentiment. For example:\n",
    "        - \"UM has too many students\" is negative.\n",
    "        - \"UM has 46,000 students\" is neither positive nor negative.\n",
    "        - \"It is good that we have so many students\" is positive.\n",
    "        - \"It is amazing that we have such an excellent number of brilliant students\" is much more positive.\n",
    "    - Our obscenity score is different. It ranges from 0 to 1, and it has a spike at both extremes. That is because of how it was measured. The score is designed to answer a yes or no question: \"Is this obscene?\" If yes, it should give a score of 1, and if no, it should give a score of 0. When it is not sure, it gives a score in between. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "\n",
    "#### Short Answer 2:\n",
    "Look at the graph for `politeness`. \n",
    "1. In a few sentences, say what a score of 0 politeness would mean. Compare this with a score of 0 in `sentiment` and 0 in `OBSCENE`.\n",
    "2. Write a few sentences comparing what 0.5 means in the three different scores.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "um_comments.sentiment.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.OBSCENE.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.politeness.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Trends over Time\n",
    "- In this lab, we're not just interested in individual comments, but in the community (in this case, a subreddit forum) and how it changes over time. \n",
    "- To study this, we're going to be using the `groupby` and `resample` functions in pandas. They're two slightly different functions that do the same basic thing:\n",
    "    - Take all of our comments and put them into groups (in our case, one group for each month).\n",
    "    - Summarize each group (e.g. by telling us how many comments are in it or what their average score is).\n",
    "- Once we have summaries for each group, we can plot them on a graph where the X axis is time. Take a look at the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the comments by month\n",
    "monthly = um_comments.resample('M', on='date')\n",
    "\n",
    "#count the number of comments in ach group\n",
    "total_comments = monthly.body.count()\n",
    "\n",
    "#show first few months\n",
    "total_comments.plot(title='Number of comments posted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can make the plots prettier with this helper function.\n",
    "Don't worry about how this code works, just run it and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(grouped, columns='id', title=None, top=None, bottom=None, \n",
    "             games=None, exams=None, classes=None, agg='mean',\n",
    "             years=[2012, 2018]):\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(14,10))\n",
    "    if bottom is not None:\n",
    "        axs.set_ylim(bottom=bottom)\n",
    "    if top is not None:\n",
    "        axs.set_ylim(top=top)\n",
    "    \n",
    "    if years is not None:\n",
    "        axs.set_xlim(left=datetime(year=years[0], month=1, day=1), \n",
    "                     right=datetime(year=years[1], month=1, day=1))\n",
    "    \n",
    "    if games is not None:\n",
    "        for g in games.iterrows():\n",
    "            if g[1].game_result == 'W':\n",
    "                axs.axvline(g[1].date, color='k', alpha=.6)\n",
    "            elif g[1].game_result == 'L':\n",
    "                axs.axvline(g[1].date, color='r', alpha=.6)\n",
    "                \n",
    "    if exams is not None:\n",
    "        for e in exams.iterrows():\n",
    "            if e[1].exams == 1:\n",
    "                axs.axvline(e[1].date, color='r', alpha=.5)\n",
    "                \n",
    "    if classes is not None:\n",
    "        for c in classes.iterrows():\n",
    "            axs.axvspan(c[1].class_start, c[1].class_end, \n",
    "                        color='g', alpha=0.35)\n",
    "                \n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "        \n",
    "        \n",
    "    if agg == 'mean':\n",
    "        for c in columns:\n",
    "            means = grouped[c].mean()\n",
    "            sems = grouped[c].sem()\n",
    "            axs.plot(means.index, means, label=c)\n",
    "            axs.fill_between(sems.index, means-(1.96*sems), \n",
    "                             means+(1.96*sems), alpha=0.5)\n",
    "\n",
    "        axs.set_ylabel('Score')\n",
    "        axs.legend()\n",
    "        if title is None:\n",
    "            title = 'Average scores with 95% confidence interval'\n",
    "            \n",
    "    elif agg == 'count':\n",
    "        for c in columns:\n",
    "            counts = grouped[c].count()\n",
    "            axs.plot(counts, label=c)\n",
    "        if title is None:\n",
    "            title = 'Number of comments per month'\n",
    "        axs.set_ylabel('Count')\n",
    "        \n",
    "    elif agg == 'unique':\n",
    "        for c in columns:\n",
    "            counts = grouped[c].nunique()\n",
    "            axs.plot(counts, label=c)\n",
    "        if title is None:\n",
    "            title = 'Number of unique ___ (user) per month'\n",
    "        axs.legend()\n",
    "        axs.set_ylabel('Count')\n",
    "        \n",
    "    axs.set_title(title)\n",
    "    axs.set_xlabel('Time')\n",
    "                \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def show_correlation(df, s1, s2):\n",
    "    tmp = df[[s1, s2]].mean()\n",
    "    tmp = tmp[tmp.index > datetime(year=2012, month=1, day=1)]\n",
    "    c = tmp.corr()\n",
    "    print(\"Correlation is:\", c.iloc[0,1].round(2))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(monthly, agg='count', years=[2011,2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(monthly, columns='author', agg='unique', years=[2011,2018])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    \n",
    "#### Short answer 3:\n",
    "    \n",
    "- Do you notice a pattern in the number of comments or active users over time?\n",
    "    - It is a little messy, but it seems like there are fewer people posting comments in the middle of each year (summer time).\n",
    "    \n",
    "**In 1-2 sentences, hypothesize why that might be happening.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about the comment scores? \n",
    "- We can plot the average score of comments each month.\n",
    "- Because the score is an average, it also has a standard error.\n",
    "- We'll write a simple helper function to make nice plots of the averages and the confidence interval around them.\n",
    "\n",
    "\n",
    "##### Try it Yourself\n",
    "- Call the function `make_plot()` with different column names to see different plots. \n",
    "- You can also call it with multiple column names in a list, like in the third example.\n",
    "- **Hint** you can change the range of the y axis by setting the arguments `top` and `bottom`. Otherwise they'll be chosen automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(monthly, columns='TOXICITY', top=.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "\n",
    "#### Short answer 4:\n",
    "1. Create a cell below and copy and paste the code above. Change the range of the y axis by setting the arguments `top` and `bottom` to produce a nice-looking plot for toxicity.\n",
    "2. Pick another score and replace the `column name` by the score you pick. Produce a nice-looking plot for the score you pick. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    \n",
    "#### Short answer 5:\n",
    "In the example below, we see toxicity and sentiment seem to have an inverse relationship: when one goes up, the other goes down. (In fact, the correlation is -0.81.)\n",
    "    \n",
    "a.  Why might this be? Write a few sentences.\n",
    "\n",
    "b. Try different combinations of variables: do other scores seem to have a relationship like this?\n",
    "-  Pick **two pairs** of scores. \n",
    "    In a few sentences each, write which you picked, whether there seems to be a relationship between them, and why that might be.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_1 = 'TOXICITY'\n",
    "score_2 = 'sentiment'\n",
    "\n",
    "show_correlation(monthly, score_1, score_2)\n",
    "make_plot(monthly, columns=[score_1, score_2], top=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Adding Events\n",
    "- Maybe some of the patterns we see in the data corrispond to events happening at the same time. \n",
    "\n",
    "#### Let's load data about when UM classes are in session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "classes = pd.read_csv('data/UM_class_periods_no_summer.tsv', sep='\\t')\n",
    "#convert dates to date data type\n",
    "classes['class_start'] = pd.to_datetime(classes.class_start)\n",
    "classes['class_end'] = pd.to_datetime(classes.class_end)\n",
    "#show the most recent information\n",
    "classes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(monthly, columns=['sentiment'], classes=classes, top=.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See a pattern?\n",
    "- The graph is green during times when classes are in session, and white otherwise.\n",
    "- Sentiment on the r/uofm subreddit seems to get more negative when Summer ends and Fall semester begins each year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "\n",
    "#### Short Answer 6:\n",
    "- Does that happen for the other scores? **Try the function with different column names** instead of `sentiment` to see. \n",
    "- 1. List the scores where it looks like their might be a pattern related to when classes are in session.\n",
    "- 2. Pick **two scores** and write a few sentences for each about why you do (or don't) see a relationship between the score and class times.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(monthly, columns=['sentiment'], classes=classes, top=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Events in Detail\n",
    "#### What about final exams?\n",
    "- Load data on exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams = pd.read_csv('data/UM_academic_calendar_no_summer.tsv', sep='\\t')\n",
    "exams['date'] = pd.to_datetime(exams.date)\n",
    "exams.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "- Don't worry about how this code works, just run it and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot2(grouped, columns='id', title=None, \n",
    "               top=None, bottom=None, colors='vega',\n",
    "               agg='mean', names = None):\n",
    "    \n",
    "    color_sets = {'UM': ['#024794', '#ffcb05', '#83b2a8',\n",
    "                         '#989c97', '#7a121c'],\n",
    "                  'vega': ['#1f77b4', '#ff7f0e', '#2ca02c', \n",
    "                           '#d62728', '#9467bd', '#8c564b',\n",
    "                           '#e377c2', '#7f7f7f', '#bcbd22']}\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(14,10))\n",
    "    if bottom is not None:\n",
    "        axs.set_ylim(bottom=bottom)\n",
    "    if top is not None:\n",
    "        axs.set_ylim(top=top)\n",
    "                \n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    if not isinstance(grouped, list):\n",
    "        grouped = [grouped]\n",
    "        names=['']\n",
    "        \n",
    "    scheme = color_sets[colors]\n",
    "          \n",
    "    axs.axvline(0, color='k', linestyle='dashed', alpha=.5)\n",
    "    i = 0\n",
    "    for g, n in zip(grouped, names):\n",
    "        if agg == 'mean':\n",
    "            for c in columns:\n",
    "                means = g[c].mean()\n",
    "                sems = g[c].sem()\n",
    "                axs.plot(means.index, means, color=scheme[i],\n",
    "                         label=n+' '+c)\n",
    "                axs.fill_between(sems.index, means-(1.96*sems), \n",
    "                                 means+(1.96*sems), \n",
    "                                 color=scheme[i], alpha=0.5)\n",
    "                i += 1\n",
    "            axs.legend()\n",
    "            axs.set_ylabel('Score')\n",
    "            if title is None:\n",
    "                title = 'Average with 95% confidence interval'\n",
    "                \n",
    "        elif agg == 'count':\n",
    "            for c in columns:\n",
    "                counts = g[c].count()\n",
    "                axs.plot(counts, color=scheme[i], label=n+' '+c)\n",
    "                i += 1\n",
    "            if title is None:\n",
    "                title = 'Number of comments'\n",
    "            axs.set_ylabel('Count')\n",
    "            \n",
    "        elif agg == 'stacked':\n",
    "            totals = None\n",
    "            for c in columns:\n",
    "                if totals == None:\n",
    "                    totals = g[c].count()\n",
    "                else: \n",
    "                    totals = totals + g[c].count()\n",
    "            \n",
    "            for c in columns:\n",
    "                pcts = g[c].count() / totals\n",
    "                axs.plot(pcts, color=scheme[i], label=n+' '+c)\n",
    "                i += 1\n",
    "                \n",
    "            if title is None:\n",
    "                title = 'Percent of comments'\n",
    "            axs.set_ylabel('Percent')\n",
    "            \n",
    "        elif agg == 'unique':\n",
    "            for c in columns:\n",
    "                counts = g[c].nunique()\n",
    "                axs.plot(counts, color=scheme[i], label=n+' '+c)\n",
    "                i += 1\n",
    "            if title is None:\n",
    "                title = 'Number of unique ___'\n",
    "            axs.set_ylabel('Count')\n",
    "            axs.legend()\n",
    "\n",
    "    axs.set_title(title)\n",
    "    axs.set_xlabel('Days from Event')\n",
    "                \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def center_on_dates(comments, dates, window_size=14):\n",
    "    subset = []\n",
    "    for d in dates.date:\n",
    "        start = d - pd.Timedelta(window_size, unit='d')\n",
    "        end = d + pd.Timedelta(window_size+1, unit='d')\n",
    "        tmp = comments[(comments.date >= start) & \n",
    "                          (comments.date <= end)].copy()\n",
    "        tmp['days'] = tmp.date.apply(lambda x: (x - d).days)\n",
    "        subset.append(tmp)\n",
    "\n",
    "    subset = pd.concat(subset)\n",
    "    return subset.groupby(by='days')\n",
    "\n",
    "def get_example_from_day(grouped, day=0, search=None, show_obscene=True):\n",
    "    # ungroups data\n",
    "    tmp = grouped.apply(lambda x: x.sample(frac=1))\n",
    "    # Selects desired day\n",
    "    tmp = tmp[tmp.days == day]\n",
    "    # optionally filters obscenity\n",
    "    if not show_obscene:\n",
    "        tmp = tmp[tmp.OBSCENE < 0.1]  \n",
    "    # optionally searches for specific words\n",
    "    if search is not None:\n",
    "        tmp = tmp[tmp.body.str.contains(search, na=False)]  \n",
    "        \n",
    "    if len(tmp) > 0:\n",
    "        tmp = tmp.sample(1).body.values[0]\n",
    "    else:\n",
    "        tmp = 'Sorry, there are no comments matching your search. Try another search or day.'\n",
    "        \n",
    "    print(tmp)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_weeks = center_on_dates(um_comments, exams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots showing posts one week before and after finals start\n",
    "- The vertical bar shows when finals start.\n",
    "    - Note that we added together the two weeks before and after finals for every semester, so what you see is the total over all. That's why the X axis is \"days since exams started\" rather than a specific date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2(exam_weeks, agg='count', bottom=0, top=5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2(exam_weeks, columns='sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2(exam_weeks, columns='INFLAMMATORY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "\n",
    "#### Short Answer 7:\n",
    "Interpreting these graphs\n",
    "- Pick **two scores** that look like they have an interesting pattern.\n",
    "- What might be causing these two patterns? Write a few sentences for each, telling us **what** the score is and **explaining your hypothesis**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "\n",
    "#### Short Answer 8: \n",
    "- Test your answers by looking at example posts from some of these days:\n",
    "    - Run the functions below multiple times: they will show you random posts from whatever day you ask for. The first shows a random comment. The second shows a random comment that includes a specific word.\n",
    "    - Try different days and words.\n",
    "- For **each of the two patterns** you observe in Short Answer 7, example comments support your hypotheses? For each, write a few sentences saying why or why not.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In function \"get_example_from_day\", you can change the number you input for \"day\", which indicates how many days from the event (in our case, the event is final exam) the comment is from. Optionally, you may want to look at comments that contain specific words. You can specify the word that you want to search for in \"search\". For example, you might want to look at comments that contain the word \"finals\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example_from_day(exam_weeks, day=10, show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example_from_day(exam_weeks, day=-1, show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example_from_day(exam_weeks, day=-3, search='finals', show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Football games\n",
    "- Load data from the subreddit for UM athletics, `r/MichiganWolverines`, and the dates of football games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_comments = pd.read_csv('data/merged/MichiganWolverines.tsv.gz', \n",
    "                              sep='\\t')\n",
    "sports_comments['date'] = pd.to_datetime(sports_comments.date)\n",
    "\n",
    "games = pd.read_csv('data/UM_football.tsv', sep='\\t')\n",
    "games['date'] = pd.to_datetime(games.date)\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = games[games.date > datetime(year=2011, month=1, day=1)]\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just for fun, what is our all time win / loss record?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.game_result.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game day sentiment\n",
    "- First, let's separate out the games we won and lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_days = center_on_dates(sports_comments, \n",
    "                           games[games.game_result == 'W'], \n",
    "                           window_size=6)\n",
    "loss_days = center_on_dates(sports_comments, \n",
    "                           games[games.game_result == 'L'], \n",
    "                           window_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at a few examples of posts from days we won and lost games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games we won\n",
    "get_example_from_day(win_days, day=0, show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games we lost\n",
    "get_example_from_day(loss_days, day=0, show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games we lost, where people mention referees\n",
    "get_example_from_day(loss_days, day=0, search='ref', show_obscene=show_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2([win_days, loss_days], names=['win', 'loss'],\n",
    "           columns='sentiment', colors='UM',\n",
    "           title='Average sentiment in r/MichiganWolverines before and after game days')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "\n",
    "#### Short Answer 9:\n",
    "Why is sentiment worse on game days, even when we win?\n",
    "- Before going further, let's think about what could cause the average sentiment of all comments to go down on game days. There are two possibilities:\n",
    "    1. A higher percent of comments are negative on game days than on other days.\n",
    "    2. The negative comments are *more negative* and/or the positive comments are *less positive* on game days\n",
    "- In a few sentences, say **whether** you think one, both, or neither of these is happening, and **why**. This is your hypothesis.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next:\n",
    "- In the next part, we separate out comments not by whether we won or lost the game that day, but by whether their sentiment was positive or negative. That will help us answer these questions:\n",
    "    - Are there more negative comments on game days? \n",
    "    - Fewer positive ones?\n",
    "    - Do the postive comments get *less* positive on game days? \n",
    "    - Do the negative ones get *more* negative?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    \n",
    "#### Short Answer 10:\n",
    "    \n",
    "1. **What hypotheses** do you have about:\n",
    "    \n",
    "        a. the relative number of positive and negative comments on game days \n",
    "    \n",
    "        b. the intensity of postive and negative comments on game days? \n",
    "2. After looking at the data, write a 1-2 sentences saying **whether** your observation supports your hypotheses and **why**. These are your preliminary findings.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_pos = center_on_dates(sports_comments[sports_comments.sentiment > 0], \n",
    "                          games, window_size=6)\n",
    "game_neg = center_on_dates(sports_comments[sports_comments.sentiment < 0], \n",
    "                           games[games.game_result == 'W'], \n",
    "                           window_size=6)\n",
    "\n",
    "def make_plot3(grouped, title=None, \n",
    "                colors='vega', names = None):\n",
    "    \n",
    "    color_sets = {'UM': ['#024794', '#ffcb05', '#83b2a8',\n",
    "                         '#989c97', '#7a121c'],\n",
    "                  'vega': ['#1f77b4', '#ff7f0e', '#2ca02c', \n",
    "                           '#d62728', '#9467bd', '#8c564b',\n",
    "                           '#e377c2', '#7f7f7f', '#bcbd22']}\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(14,10))\n",
    "                    \n",
    "    if not isinstance(grouped, list):\n",
    "        grouped = [grouped]\n",
    "        names=['']\n",
    "        \n",
    "    scheme = color_sets[colors]\n",
    "          \n",
    "    axs.axvline(0, color='k', linestyle='dashed', alpha=.5)\n",
    "    i = 0\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for g, n in zip(grouped, names):                    \n",
    "        tmp = g[['id']].count().copy()\n",
    "        tmp.columns = [n]\n",
    "        df = df.merge(tmp, left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "    totals = df.sum(axis=1)\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c] / totals\n",
    "        \n",
    "    axs.stackplot(df.index, df.T, labels=df.columns, colors=scheme)\n",
    "        \n",
    "    if title is None:\n",
    "        title = 'Percent of comments'\n",
    "    else:\n",
    "        axs.set_title(title)\n",
    "        \n",
    "    axs.set_ylabel('Percent')          \n",
    "    axs.set_xlabel('Days from Event')\n",
    "    axs.legend()\n",
    "                \n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot3([game_pos, game_neg], names=['pos', 'neg'],\n",
    "           colors='UM',\n",
    "           title='Relative number of positive and negative comments in r/MichiganWolverines before and after game days')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2([game_pos, game_neg], names=['pos', 'neg'],\n",
    "           columns='sentiment', colors='UM',\n",
    "           title='Average sentiment of comments in r/MichiganWolverines before and after game days')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your response here:**\n",
    "...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we learned:\n",
    "1. What reddit is, and what comment data looks like.\n",
    "2. Various ways of scoring comments to summarize their contents.\n",
    "3. The difficulty of getting good scores.\n",
    "4. Grouping data by time and showing trends in average comment scores.\n",
    "5. Comparing time series data with events.\n",
    "\n",
    "### Reflection 1: write a brief proposal:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "\n",
    "Write a **2-paragraph proposal** to expand on the analysis of the cause of low sentiment on game days.  \n",
    "- 1. (One of the explanations is that Saturdays cause negative sentiments - see optional for the analysis.) What **other causes** can you think of? \n",
    "- 2. What could you do to further **test** your preliminary findings? That is, what additional analysis could you do to check if they were right? (You don't need to actually do the analysis.) \n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "\n",
    "**Hints**:\n",
    "- What other scores you want to look at (that might be related to sentiment)?  Why?\n",
    "     - recall SA5: there is an inverse relationship between toxicity and sentiment. Are there relationships between sentiment and other scores?\n",
    "- Are there outside factors that might be causing the pattern we see? What are they, and how might you test them? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î**Write your proposal here:**\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional\n",
    "\n",
    "## Do Saturdays cause negative comments? \n",
    "- This code will help us find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def get_dates(from_date, to_date, day_list=[5]):\n",
    "    tmp_list = list()\n",
    "    date_list = list()\n",
    "    for x in range((to_date - from_date).days+1):\n",
    "        tmp_list.append(from_date + timedelta(days=x))\n",
    "    for date_record in tmp_list:\n",
    "        if date_record.weekday() in day_list:\n",
    "            date_list.append(date_record)\n",
    " \n",
    "    return date_list\n",
    "\n",
    "dates = get_dates(datetime(year=2012, month=1, day=1), \n",
    "          datetime(year=2018, month=1, day=1), \n",
    "          day_list=[5])\n",
    "\n",
    "gd = set(games.date.tolist())\n",
    "\n",
    "sats = pd.DataFrame(dates).rename(columns={0: 'date'})\n",
    "sats = set(sats.date) - gd\n",
    "sats = pd.DataFrame(list(sats)).rename(columns={0: 'date'})\n",
    "\n",
    "saturdays = center_on_dates(sports_comments, \n",
    "                            sats, window_size=6)\n",
    "\n",
    "make_plot2([win_days, loss_days, saturdays], \n",
    "           names=['win', 'loss', 'saturday'],\n",
    "           columns='sentiment', colors='vega',\n",
    "           title='Average sentiment in r/MichiganWolverines before and after game days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like game days are worse than regular Saturdays!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
