{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwlock/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import ipyparallel\n",
    "import os\n",
    "import sys\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "c = ipyparallel.Client()\n",
    "view = c.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(txt):\n",
    "    sents = sent_tokenize(txt)\n",
    "    model = SentimentIntensityAnalyzer()\n",
    "    results = []\n",
    "    for s in sents:\n",
    "        results.append(model.polarity_scores(s)['compound'])\n",
    "    return np.mean(results)\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25984999999999997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"Here is some sample text. THe text makes me happy. Much like my amazing cat. But not like that garbage windows.\"\n",
    "get_sentiment(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    import pandas as pd\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    import numpy as np\n",
    "    \n",
    "    def get_sentiment(txt):\n",
    "        sents = sent_tokenize(str(txt))\n",
    "        model = SentimentIntensityAnalyzer()\n",
    "        results = []\n",
    "        for s in sents:\n",
    "            results.append(model.polarity_scores(s)['compound'])\n",
    "        return np.mean(results)\n",
    "\n",
    "    df['sentiment'] = df.body.apply(get_sentiment)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding TwoXChromosomes.tsv\n",
      "already finished demsocialist.tsv\n",
      "already finished puppies.tsv\n",
      "already finished republicans.tsv\n",
      "already finished CatGifs.tsv\n",
      "already finished cats.tsv\n",
      "already finished GreenParty.tsv\n",
      "already finished msu.tsv\n",
      "already finished StartledCats.tsv\n",
      "already finished uofm.tsv\n",
      "already finished CatsStandingUp.tsv\n",
      "already finished dogpictures.tsv\n",
      "already finished OSU.tsv\n",
      "already finished communism.tsv\n",
      "already finished TrollXChromosomes_short.tsv\n",
      "already finished democrats.tsv\n",
      "already finished Liberal.tsv\n",
      "already finished dogs_short.tsv\n",
      "already finished socialism_short.tsv\n",
      "already finished TwoXChromosomes_short.tsv\n",
      "already finished Libertarian_short.tsv\n",
      "already finished progressive.tsv\n",
      "already finished FULLCOMMUNISM.tsv\n",
      "already finished Republican.tsv\n",
      "already finished Dogtraining.tsv\n",
      "already finished NeutralPolitics.tsv\n",
      "already finished socialism.tsv\n",
      "already finished dogs.tsv\n",
      "adding TrollXChromosomes.tsv\n",
      "adding Libertarian.tsv\n"
     ]
    }
   ],
   "source": [
    "def get_files_by_file_size(dirname, reverse=False):\n",
    "    \"\"\" Return list of file paths in directory sorted by file size \"\"\"\n",
    "\n",
    "    l = len(dirname)\n",
    "    # Get list of files\n",
    "    filepaths = []\n",
    "    for basename in os.listdir(dirname):\n",
    "        filename = os.path.join(dirname, basename)\n",
    "        if os.path.isfile(filename):\n",
    "            filepaths.append(filename)\n",
    "    for i in range(len(filepaths)):\n",
    "        filepaths[i] = (filepaths[i], os.path.getsize(filepaths[i]))\n",
    "    filepaths.sort(key=lambda filename: filename[1], reverse=reverse)\n",
    "    for i in range(len(filepaths)):\n",
    "        filepaths[i] = filepaths[i][0][l+1:]\n",
    "\n",
    "    return filepaths\n",
    "           \n",
    "def get_jobs():\n",
    "    jobs = []\n",
    "    \n",
    "    files = get_files_by_file_size('../sampled', reverse=False)\n",
    "    if 'TwoXChromosomes.tsv' in files:\n",
    "        files.remove('TwoXChromosomes.tsv')\n",
    "        files.insert(0, 'TwoXChromosomes.tsv')\n",
    "    done = os.listdir('data/sentiment/')\n",
    "    \n",
    "    for f in files:\n",
    "        if f.endswith('tsv'):\n",
    "            if f in done:\n",
    "                print('already finished', f)\n",
    "                pass\n",
    "            else:\n",
    "                print('adding', f)\n",
    "                tmp = {}\n",
    "                tmp['file'] = '/home/jwlock/research/reddit/sampled/'+f\n",
    "                tmp['subreddit'] = f[:-4]\n",
    "                jobs.append(tmp)\n",
    "    \n",
    "    return jobs\n",
    "\n",
    "jobs = get_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7243/15619 tasks finished after 7186 s"
     ]
    }
   ],
   "source": [
    "while len(jobs)>0:\n",
    "    j = jobs[0]\n",
    "    print('Working on', j['subreddit'])\n",
    "    df = pd.read_csv(j['file'], sep='\\t')\n",
    "    chunks = chunker(df, 500)\n",
    "    result = view.map_async(process_df, chunks)\n",
    "    result.wait_interactive()\n",
    "    df = pd.concat(result)\n",
    "    df.to_csv('data/sentiment/'+j['subreddit']+'.tsv', sep='\\t', index=False)\n",
    "    jobs = get_jobs()\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
