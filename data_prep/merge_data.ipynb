{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for merging together various comment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories with data files in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_files = os.listdir('../data/perspective/')\n",
    "politeness_files = os.listdir('../data/politeness/')\n",
    "sentiment_files = os.listdir('../data/sentiment/')\n",
    "pn_files = os.listdir('../data/pej_nouns/')\n",
    "raw_files = os.listdir('../data/raw/')\n",
    "\n",
    "all_files = set(perspective_files + politeness_files)\n",
    "#all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out which scores we have for which subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = {}\n",
    "\n",
    "for f in all_files:\n",
    "    if f.endswith('.tsv'):\n",
    "        tmp = []\n",
    "        if f in raw_files:\n",
    "            tmp.append('../data/raw/')\n",
    "        if f in perspective_files:\n",
    "            tmp.append('../data/perspective/')\n",
    "        if f in politeness_files:\n",
    "            tmp.append('../data/politeness/')\n",
    "        if f in sentiment_files:\n",
    "            tmp.append('../data/sentiment/')\n",
    "        if f in pn_files:\n",
    "            tmp.append('../data/pej_nouns/')\n",
    "        to_merge[f] = tmp\n",
    "to_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show example columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('../data/merged/TwoXChromosomes.tsv', sep='\\t')\n",
    "tmp.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('../data/perspective/TwoXChromosomes.tsv', sep='\\t')\n",
    "tmp.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do  the merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# columns we're not interested in\n",
    "cols_to_drop = set(['approved_by', 'author_cakeday', 'author_flair_css_class', \n",
    "                    'author_flair_text', 'banned_at_utc', 'banned_by', \n",
    "                    'can_gild', 'can_mod_post', 'collapsed_reason', 'created',\n",
    "                    'distinguished', 'downs', 'gilded', 'likes', 'link_id', \n",
    "                    'num_reports', 'removal_reason', 'report_reasons',\n",
    "                    'retrieved_on', 'saved', 'score_hidden', 'subreddit_id', \n",
    "                    'Unnamed: 0', 'approved_at_utc', 'name', 'gilded'])\n",
    "\n",
    "# final column order desired\n",
    "out_order = ['date', 'author', 'body', 'politeness', 'sentiment', \n",
    "               'controversiality', 'TOXICITY', 'ATTACK_ON_COMMENTER', \n",
    "               'INFLAMMATORY', 'LIKELY_TO_REJECT', 'OBSCENE', \n",
    "               'SEVERE_TOXICITY', 'ATTACK_ON_AUTHOR', 'SPAM', \n",
    "               'UNSUBSTANTIAL', 'INCOHERENT', 'pej_nouns', 'ups', 'edited', 'id', \n",
    "               'is_submitter', 'link_id', 'parent_id', 'replies', \n",
    "               'score', 'subreddit', 'stickied',  'archived', 'collapsed']\n",
    "\n",
    "# iterates over each subreddit we have data for\n",
    "for k,v in to_merge.items():\n",
    "    print(k)\n",
    "    df = pd.DataFrame()\n",
    "    # iterates over each file we need to merge for that subreddit\n",
    "    for p in v:\n",
    "        print(p)\n",
    "        #read data\n",
    "        tmp = pd.read_csv(p+k, sep='\\t')\n",
    "        #figure out which columns we don't already have\n",
    "        keep = set(tmp.columns.values) - set(df.columns.values)\n",
    "        keep.add('id') #add ID to merge on, even though we have it already\n",
    "        keep = list(keep - cols_to_drop) # ignore cols we don't want\n",
    "        tmp = tmp[keep]\n",
    "        #print(tmp.columns.values)\n",
    "        if df.shape[1]==0: #first iteration just take the dataframe\n",
    "            df=tmp\n",
    "        else: # future iterations we merge them\n",
    "            df = df.merge(tmp, on='id')\n",
    "    \n",
    "    # make our dates real dates\n",
    "    df['date'] = pd.to_datetime(df.created_utc, unit='s')\n",
    "    \n",
    "    #print(df.columns.values)\n",
    "    \n",
    "    #figure out which scores we don't have yet\n",
    "    missing = set(out_order) - set(df.columns.values) \n",
    "    for m in missing:\n",
    "        out_order.remove(m)\n",
    "        \n",
    "    #reorder the columns \n",
    "    df = df[out_order]\n",
    "    #print(df.columns.values)\n",
    "    #save the merged scores\n",
    "    df.to_csv('../data/merged/'+k, sep='\\t', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
