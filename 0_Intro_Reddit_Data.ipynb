{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Introduction to Reddit Data\n",
    "\n",
    "In this lab, we'll cover:\n",
    "- What reddit data look like\n",
    "- Several ways to summarize the conversation's tone\n",
    "- Evaluation of data over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data\n",
    "- Data files with Reddit comments are publicly available many places online, including torrents, google's BigQuery, and several data hosting websites. UM keeps a full copy in our Advanced Research Computing resources.\n",
    "- Reddit is one of the biggest sites on the internet. \n",
    "    - It has over 3.5 billion comments, and the data take up several TB of disk space (`1 TB = 1024 GB`)! \n",
    "    - This makes working with the data difficult.\n",
    "    - For simplicity, we went ahead and used some big data tools like `pyspark` and `hadoop` to go through all the comments and select out smaller sets to work with in this lab. \n",
    "- Let's start by looking at just the comments from the subreddit community for the University of Michigan\n",
    "    - This file is only 34 MB: a more managable size!\n",
    "    - The `shape` property tells us that there are 66 thousand rows (comments) and 28 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "um_comments = pd.read_csv('data/merged/uofm.tsv', sep='\\t')\n",
    "\n",
    "#convert our dates to the date data type\n",
    "um_comments['date'] = pd.to_datetime(um_comments.date)\n",
    "#show the shape of our table\n",
    "um_comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What information do we have about each comment?\n",
    "- We have a lot! Here are some of the most interesting columns:\n",
    "    - `body` the text of the comment\n",
    "    - `author` the username of the person who posted it\n",
    "    - `date` when the comment was made\n",
    "    - `subreddit` which community a comment is from. Here, they're all from `r/uofm`\n",
    "    - `politeness` scores, computed by the [Stanford NLP group's software](https://www.cs.cornell.edu/~cristian/Politeness.html), tell us how \"polite\" a comment is, from 0 (not at all) to 1 (very polite). The program that gives these scores was designed primarily for comments where someone was replying to a request.\n",
    "    - `sentiment` (how positive or negative a comment is), computed by the [VADER program in NLTK](http://www.nltk.org/_modules/nltk/sentiment/vader.html). (-1 is very negative, 0 is neutral, and 1 is very positive). \n",
    "    - `pej_nouns`: Sometimes when an adjective for people is used as a noun, it takes on a pejorative meaning. Research has found this is often true for the words \"female,\" \"gay,\" \"poor,\" and \"illegal,\" so this column counts the number of times those words (or versions of them like \"females\") are used as nouns. For more information, see this paper:\n",
    "        - Palmer, Alexis, Melissa Robinson, and Kristy Philips. 2017. “[Illegal Is Not a Noun: Linguistic Form for Detection of Pejorative Nominalizations](http://www.aclweb.org/anthology/W17-3014).” Pp. 91–100 in *Proceedings of the First Workshop on Abusive Language Online.* Vancouver.\n",
    "    - Several scores from the [Perspective API](https://www.perspectiveapi.com/). In this project, Google and Jigsaw teamed up to build automatic systems for finding bad comments. We used their program to score these comments already, and the scores are saved in the file.\n",
    "        - `ATTACK_ON_COMMENTER` the probability that this comment is a personal attack on another commenter \n",
    "        - `INCOHERENT` whether the comment seems to make sense (high values don't make sense).\n",
    "        - `INFLAMMATORY` how inflammatory the comment is\n",
    "        - `LIKELY_TO_REJECT` the liklihood that New York Times comment editors would reject  the comment if it was posted on their site \n",
    "        - `OBSCENE` probability that the comment is obscene\n",
    "        - `TOXICITY` probability that the comment is 'toxic' for community discussion\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example comments\n",
    "- This randomly selects one of the comments and shows the text. \n",
    "- Run it multiple times to see different randomly chosen comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(um_comments.sample(1).body.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function for finding examples of comments that score high or low\n",
    "Run this code and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example(data, column, where='high'):\n",
    "    #pick whether to use high or low scoring comments\n",
    "    if where == 'high':\n",
    "        asc = False\n",
    "    else:\n",
    "        asc = True\n",
    "    #Select the 100 most extreme comments in this column\n",
    "    df = data.sort_values(by=column, ascending=asc).head(100)\n",
    "    #pick one at random and print the text of it\n",
    "    print(df.sample(1).body.iloc[0])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do all those scores mean? (They're not perfect!)\n",
    "- **Run the code below, trying different column names** to see examples of comments that scored high or low in each measure.  \n",
    "    - The function `get_example()` picks a comment at random, so run it more than once with `alt`+`enter` and you'll see different comments.\n",
    "    - Do you notice a pattern with the types of comments that come up? \n",
    "    - Do any of the scores seem to mean something a little different than you expected?\n",
    "- Note that the scores don't always seem right. For example, sometimes a comment that scored high in `ATTACK_ON_COMMENTER` isn't actually a personal attack.\n",
    "    - The scores were made by some of the most advanced software for this in the world, and they're still not perfect. This reminds us just how hard it is for computers to understand human language.\n",
    "- Still, most of the scores seem about right. And, as we know from statistics, we can still make inferences about average scores even when there are some errors in our measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='sentiment', where='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='sentiment', where='low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='politeness', where='low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, \n",
    "            column='ATTACK_ON_COMMENTER', where='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='TOXICITY', where='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(data=um_comments, column='OBSCENE', where='high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a feel for our data\n",
    "- One of the first things to do with any data is plot it. We want to get a feel for what's in it. Take a look at the histograms below.\n",
    "- Some of the scores are normally distributed, like sentiment and politeness. \n",
    "    - What might this mean?\n",
    "    - Why might there be a spike of comments with exactly 0 (totally neutral) sentiment?\n",
    "- The distributions of other scores, like personal attacks and obscenity are very skewed. \n",
    "    - Most comments are nice (low scores), but a few are not (high scores). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "um_comments.sentiment.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.politeness.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.ATTACK_ON_COMMENTER.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.OBSCENE.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_comments.TOXICITY.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeing trends over time\n",
    "- In this lab, we're not just interested in individual comments, but in the community (in this case, a subreddit forum) and how it changes over time. \n",
    "- To study this, we're going to be using the `groupby` and `resample` functions in pandas. They're two slightly different functions that do the same basic thing:\n",
    "    - Take all of our comments and put them into groups (in our case, one group for each month).\n",
    "    - Summarize each group (e.g. by telling us how many comments are in it or what their average score is).\n",
    "- Once we have summaries for each group, we can plot them on a graph where the X axis is time. Take a look at the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the comments by month\n",
    "monthly = um_comments.resample('M', on='date')\n",
    "\n",
    "#count the number of comments in ach group\n",
    "total_comments = monthly.body.count()\n",
    "\n",
    "#show first few months\n",
    "total_comments.plot(title='Number of comments posted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can make the plots prettier with this helper function.\n",
    "Don't worry about how this code works, just run it and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(grouped, columns='id', title=None, top=None, bottom=None, \n",
    "             games=None, exams=None, classes=None, agg='mean',\n",
    "             years=[2012, 2018]):\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(14,10))\n",
    "    if bottom is not None:\n",
    "        axs.set_ylim(bottom=bottom)\n",
    "    if top is not None:\n",
    "        axs.set_ylim(top=top)\n",
    "    \n",
    "    if years is not None:\n",
    "        axs.set_xlim(left=datetime(year=years[0], month=1, day=1), \n",
    "                     right=datetime(year=years[1], month=1, day=1))\n",
    "    \n",
    "    if games is not None:\n",
    "        for g in games.iterrows():\n",
    "            if g[1].game_result == 'W':\n",
    "                axs.axvline(g[1].date, color='k', alpha=.6)\n",
    "            elif g[1].game_result == 'L':\n",
    "                axs.axvline(g[1].date, color='r', alpha=.6)\n",
    "                \n",
    "    if exams is not None:\n",
    "        for e in exams.iterrows():\n",
    "            if e[1].exams == 1:\n",
    "                axs.axvline(e[1].date, color='r', alpha=.5)\n",
    "                \n",
    "    if classes is not None:\n",
    "        for c in classes.iterrows():\n",
    "            axs.axvspan(c[1].class_start, c[1].class_end, \n",
    "                        color='g', alpha=0.35)\n",
    "                \n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "        \n",
    "        \n",
    "    if agg == 'mean':\n",
    "        for c in columns:\n",
    "            means = grouped[c].mean()\n",
    "            sems = grouped[c].sem()\n",
    "            axs.plot(means.index, means)\n",
    "            axs.fill_between(sems.index, means-(1.96*sems), \n",
    "                             means+(1.96*sems), alpha=0.5)\n",
    "\n",
    "        if title is None:\n",
    "            title = 'Average scores with 95% confidence interval'\n",
    "    elif agg == 'count':\n",
    "        for c in columns:\n",
    "            counts = grouped[c].count()\n",
    "            axs.plot(counts)\n",
    "        if title is None:\n",
    "            title = 'Number of comments per month'\n",
    "    elif agg == 'unique':\n",
    "        for c in columns:\n",
    "            counts = grouped[c].nunique()\n",
    "            axs.plot(counts)\n",
    "        if title is None:\n",
    "            title = 'Number of unique ___ per month'\n",
    "    axs.set_title(title)\n",
    "    axs.set_xlabel('Time')\n",
    "\n",
    "    if len(columns) == 1:\n",
    "        axs.set_ylabel(columns[0])\n",
    "    else:\n",
    "        axs.legend()\n",
    "                \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(monthly, agg='count', years=[2011,2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(monthly, columns='author', agg='unique', years=[2011,2018])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for patterns\n",
    "- Do you notice a pattern in the number of comments or active users over time?\n",
    "    - It is a little messy, but it seems like there are less people posting comments in the middle of each year (summer time). Why might that be? \n",
    "    \n",
    "### What about the comment scores? \n",
    "- We can plot the average score of comments each month.\n",
    "- Because the score is an average, it also has a standard error.\n",
    "- We'll write a simple helper function to make nice plots of the averages and the confidence interval around them.\n",
    "\n",
    "\n",
    "# Try it yourself:\n",
    "- Call the function `make_plot()` with different column names to see different plots. \n",
    "- You can also call it with multiple column names in a list, like in the third example.\n",
    "- **Hint** you can change the range of the y axis by setting the arguments `top` and `bottom`. Otherwise they'll be chosen automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_plot(monthly, columns='TOXICITY', top=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect: look for relationships\n",
    "- In the example below, we see toxicity and sentiment seem to have an inverse relationship: when one goes up, the other goes down. (In fact, the correlation is -0.8)\n",
    "    - Why might this be?\n",
    "- Try different combinations of variables: do other scores seem to have a relationship like this?\n",
    "- Write a few sentences for each question below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect here\n",
    "- . \n",
    "- ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_plot(monthly, columns=['TOXICITY', 'sentiment'], top=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding events\n",
    "- Maybe some of the patterns we see in the data corrispond to events happening at the same time. \n",
    "\n",
    "#### Let's load data about when UM classes are in session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "classes = pd.read_csv('data/UM_class_periods_no_summer.tsv', sep='\\t')\n",
    "#convert dates to date data type\n",
    "classes['class_start'] = pd.to_datetime(classes.class_start)\n",
    "classes['class_end'] = pd.to_datetime(classes.class_end)\n",
    "#show the most recent information\n",
    "classes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(monthly, columns=['sentiment'], classes=classes, top=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See a pattern?\n",
    "- The graph is green during times when classes are in session, and white otherwise.\n",
    "- Sentiment on the r/uofm subreddit seems to get more negative when Summer ends and Fall semester begins each year.\n",
    "\n",
    "# Try it youself\n",
    "- Does that happen for the other scores? **Try the function with different column names** instead of `sentiment` to see. Write a list of scores where you see a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect here\n",
    "- .\n",
    "- ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about final exams?\n",
    "- Load data on exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams = pd.read_csv('data/UM_academic_calendar_no_summer.tsv', sep='\\t')\n",
    "exams['date'] = pd.to_datetime(exams.date)\n",
    "exams.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "- Don't worry about how this code works, just run it and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot2(grouped, columns='id', title=None, \n",
    "               top=None, bottom=None, colors='vega',\n",
    "               agg='mean', names = None):\n",
    "    \n",
    "    color_sets = {'UM': ['#024794', '#ffcb05', '#83b2a8',\n",
    "                         '#989c97', '#7a121c'],\n",
    "                  'vega': ['#1f77b4', '#ff7f0e', '#2ca02c', \n",
    "                           '#d62728', '#9467bd', '#8c564b',\n",
    "                           '#e377c2', '#7f7f7f', '#bcbd22']}\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(14,10))\n",
    "    if bottom is not None:\n",
    "        axs.set_ylim(bottom=bottom)\n",
    "    if top is not None:\n",
    "        axs.set_ylim(top=top)\n",
    "                \n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    if not isinstance(grouped, list):\n",
    "        grouped = [grouped]\n",
    "        names=['']\n",
    "        \n",
    "    scheme = color_sets[colors]\n",
    "          \n",
    "    axs.axvline(0, color='k', linestyle='dashed', alpha=.5)\n",
    "    i = 0\n",
    "    for g, n in zip(grouped, names):\n",
    "        if agg == 'mean':\n",
    "            for c in columns:\n",
    "                means = g[c].mean()\n",
    "                sems = g[c].sem()\n",
    "                axs.plot(means.index, means, color=scheme[i],\n",
    "                         label=n+' '+c)\n",
    "                axs.fill_between(sems.index, means-(1.96*sems), \n",
    "                                 means+(1.96*sems), \n",
    "                                 color=scheme[i], alpha=0.5)\n",
    "                i += 1\n",
    "\n",
    "            if title is None:\n",
    "                title = 'Average with 95% confidence interval'\n",
    "        elif agg == 'count':\n",
    "            for c in columns:\n",
    "                counts = g[c].count()\n",
    "                axs.plot(counts, color=scheme[i], label=n+' '+c)\n",
    "                i += 1\n",
    "            if title is None:\n",
    "                title = 'Number of comments'\n",
    "            axs.set_ylabel('Count')\n",
    "        elif agg == 'unique':\n",
    "            for c in columns:\n",
    "                counts = g[c].nunique()\n",
    "                axs.plot(counts, color=scheme[i], label=n+' '+c)\n",
    "                i += 1\n",
    "            if title is None:\n",
    "                title = 'Number of unique ___'\n",
    "            axs.set_ylabel('Count')\n",
    "\n",
    "    axs.set_title(title)\n",
    "    axs.set_xlabel('Days from Event')\n",
    "\n",
    "    if len(columns) == 1:\n",
    "        axs.set_ylabel(columns[0])\n",
    "        if len(grouped) > 1:\n",
    "            axs.legend()\n",
    "    else:\n",
    "        axs.legend()\n",
    "                \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def center_on_dates(comments, dates, window_size=14):\n",
    "    subset = []\n",
    "    for d in dates.date:\n",
    "        start = d - pd.Timedelta(window_size, unit='d')\n",
    "        end = d + pd.Timedelta(window_size+1, unit='d')\n",
    "        tmp = comments[(comments.date >= start) & \n",
    "                          (comments.date <= end)].copy()\n",
    "        tmp['days'] = tmp.date.apply(lambda x: (x - d).days)\n",
    "        subset.append(tmp)\n",
    "\n",
    "    subset = pd.concat(subset)\n",
    "    return subset.groupby(by='days')\n",
    "\n",
    "def get_example_from_day(grouped, day=0, search=None):\n",
    "    if search is not None:\n",
    "        tmp = grouped.apply(lambda x: x.sample(frac=1))\n",
    "        tmp = tmp[tmp.body.str.contains(search, na=False)]  \n",
    "        tmp = tmp[tmp.days == day]\n",
    "        if len(tmp) > 0:\n",
    "            tmp = tmp.sample(1).body.values[0]\n",
    "        else:\n",
    "            tmp = 'Sorry, there are no comments with the search term \"'\n",
    "            tmp += search\n",
    "            tmp += '\" on day '\n",
    "            tmp += str(day)\n",
    "            tmp += \". Try another search or day.\"\n",
    "    else:\n",
    "        tmp = grouped.apply(lambda x: x.sample(1))\n",
    "        tmp = tmp[tmp.days == day].body.values[0]\n",
    "    print(tmp)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_weeks = center_on_dates(um_comments, exams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots showing posts one week before and after finals start\n",
    "- The vertical bar shows when finals start.\n",
    "    - Note that we added together the two weeks before and after finals for every semester, so what you see is the total over all. That's why the X axis is \"days since exams started\" rather than a specific date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2(exam_weeks, agg='count', bottom=0, top=5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2(exam_weeks, columns='sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2(exam_weeks, columns='INFLAMMATORY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect\n",
    "### Interpreting these graphs\n",
    "- Do you see any interesting patterns? Pick one.\n",
    "- What might be causing these two patterns? Write a few sentences. Hints:\n",
    "    - Do you think different people are posting on different days?\n",
    "    - Do you think the same people might post different things on different days?\n",
    "- Test your answers by looking at example posts from some of these days:\n",
    "    - Run the function below multiple times: it will show you random posts from whatever day you ask for. \n",
    "    - Try asking it for different days.\n",
    "- Try the plots above with different scores. Do exams corrispond with trends in scores other than sentiment? Write a few sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect here:\n",
    "- .\n",
    "- .\n",
    "- ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example_from_day(exam_weeks, day=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also search for comments with specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example_from_day(exam_weeks, day=10, search='finals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Football games\n",
    "- Load data from the subreddit for UM athletics, `r/MichiganWolverines`, and the dates of football games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_comments = pd.read_csv('data/merged/MichiganWolverines.tsv', \n",
    "                              sep='\\t')\n",
    "sports_comments['date'] = pd.to_datetime(sports_comments.date)\n",
    "\n",
    "games = pd.read_csv('data/UM_football.tsv', sep='\\t')\n",
    "games['date'] = pd.to_datetime(games.date)\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = games[games.date > datetime(year=2011, month=1, day=1)]\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just for fun, what is our all time win / loss record?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.game_result.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game day sentiment\n",
    "- First, let's separate out the games we won and lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_days = center_on_dates(sports_comments, \n",
    "                           games[games.game_result == 'W'], \n",
    "                           window_size=7)\n",
    "loss_days = center_on_dates(sports_comments, \n",
    "                           games[games.game_result == 'L'], \n",
    "                           window_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at a few examples of posts from days we won and lost games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games we won\n",
    "get_example_from_day(win_days, day=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games we lost\n",
    "get_example_from_day(loss_days, day=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games we lost, where people mention referees\n",
    "get_example_from_day(loss_days, day=0, search='ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2([win_days, loss_days], names=['win', 'loss'],\n",
    "           columns='sentiment', \n",
    "           colors='UM',\n",
    "           title='Average sentiment in r/MichiganWolverines before and after game days')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect\n",
    "### Why is sentiment worse on game days, even when we win?\n",
    "- Before going further, come up with a hypothesis that might explain lower sentiment on game days, regardless of whether we win. Write it down.\n",
    "- In the next part, we separate out comments not by whether we won or lost the game that day, but by whether their sentiment was positive or negative. That will help us answer these questions:\n",
    "    - Are there more negative comments on game days? \n",
    "    - Fewer positive ones?\n",
    "    - Do the postive comments get *less* positive on game days? \n",
    "    - Do the negative ones get *more* negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis here\n",
    "- ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_pos = center_on_dates(sports_comments[sports_comments.sentiment > 0], \n",
    "                          games, window_size=7)\n",
    "game_neg = center_on_dates(sports_comments[sports_comments.sentiment < 0], \n",
    "                           games[games.game_result == 'W'], \n",
    "                           window_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2([game_pos, game_neg], names=['pos', 'neg'],\n",
    "           columns='id', agg='count', colors='UM',\n",
    "           title='Average number of comments in r/MichiganWolverines before and after game days')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot2([game_pos, game_neg], names=['pos', 'neg'],\n",
    "           columns='sentiment', colors='UM',\n",
    "           title='Average number of comments in r/MichiganWolverines before and after game days')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we learned:\n",
    "1. What reddit is, and what comment data looks like.\n",
    "2. Various ways of scoring comments to summarize their contents.\n",
    "3. The difficulty of getting good scores.\n",
    "4. Grouping data by time and showing trends in average comment scores.\n",
    "5. Comparing time series data with events.\n",
    "\n",
    "# Reflect\n",
    "### Write a brief proposal:\n",
    "Write a 2 paragraph proposal to expand on this analysis. Answer the following questions:\n",
    "1. What would you do to test our preliminary findings? That is, what analysis could you do to check if our initial guesses were right?\n",
    "2. What outside factors would you need to control for or look at in your comparison?\n",
    "    - **Hint:** Game days are usually Saturdays. What if our findings happen because it is Saturday, not because it is a game day? \n",
    "3. What other scores might you want to look at? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write your proposal here\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional\n",
    "\n",
    "## Do Saturdays cause negative comments? \n",
    "- This code will help us find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def get_dates(from_date, to_date, day_list=[5]):\n",
    "    tmp_list = list()\n",
    "    date_list = list()\n",
    "    for x in range((to_date - from_date).days+1):\n",
    "        tmp_list.append(from_date + timedelta(days=x))\n",
    "    for date_record in tmp_list:\n",
    "        if date_record.weekday() in day_list:\n",
    "            date_list.append(date_record)\n",
    " \n",
    "    return date_list\n",
    "\n",
    "dates = get_dates(datetime(year=2012, month=1, day=1), \n",
    "          datetime(year=2018, month=1, day=1), \n",
    "          day_list=[5])\n",
    "\n",
    "gd = set(games.date.tolist())\n",
    "\n",
    "sats = pd.DataFrame(dates).rename(columns={0: 'date'})\n",
    "sats = set(sats.date) - gd\n",
    "sats = pd.DataFrame(list(sats)).rename(columns={0: 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturdays = center_on_dates(sports_comments, \n",
    "                           sats, \n",
    "                           window_size=7)\n",
    "\n",
    "make_plot2([win_days, loss_days, saturdays], \n",
    "           colors='vega',\n",
    "           names=['win', 'loss', 'saturday'],\n",
    "           columns='sentiment', \n",
    "           title='Average sentiment in r/MichiganWolverines before and after game days')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like game days are worse than regular Saturdays!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
